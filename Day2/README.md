# Day 2

## Seminar: Extracting Latent Moral Information from Text with ChatGPT
*Speaker: Justin Chun-Ting Ho*

Justin began his talk by discussing the debate around morality. 
Justin pointed out that although people discuss moriality often, they rarely agree on what is the right thing, how to do the right thing, and what is relevant to morality.
Justin introduced two types of moral systems: individualising and binding.

Justin then introduced the moral foundation theory, which states that moral foundations are innate, universal, and intuitative. 
There are five foundations: care/harm, fairness/cheating, loyalty/betrayal, authority/subversion, and sanctity/degradation.

Justin's research is focused on measuring moral foundations from text. 
The fact that no one agrees on morality and what is moral is a major barrier which Justin must consider in his research.

Justin is now investigating if he can use ChatGPT in his research. 
ChatGPT is a large language model (LLM). 
It is trained on a large coprups of text data, and can provide answers to questions in a way that looks similar to text written by humans.
However, ChatGPT does not know the context of words in the same way humans do.

In his research, Justin compared different methods of measuring moral foundation in text:

1. Content analysis
2. Moral foundation dictionary
3. crowdsourced
4. ChatGPT (zero-shot and dictionary assisted)

Justin found that the dictionary-assisted ChatGPT approach seemed to perform similarly to the dictionary approach. 
However, ChatGPT did hallucinate and was possibly unreliable.
